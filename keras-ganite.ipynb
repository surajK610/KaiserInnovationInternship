{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply, Lambda\n",
    "from keras.layers import BatchNormalization, Activation, Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.constraints import NonNeg\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customDiscriminatorLoss(tTrue,tPred):\n",
    "    return K.sum(K.binary_crossentropy(tTrue[0],tPred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customGeneratorLoss(yTrue,yPred,a=1):\n",
    "    return a*K.sum((yTrue[:,-1]-yPred[:,-1])**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customCombinedLoss(ytTrue,ytPred,a=1):\n",
    "    return K.sum(customDiscriminatorLoss(ytTrue[1],ytPred[1]),customGeneratorLoss(ytTrue[0],ytPred[0],a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):\n",
    "    cond = K.greater(x,0)\n",
    "    return K.switch(cond,x,K.minimum(-100.,x))\n",
    "\n",
    "get_custom_objects().update({'custom_activation': Activation(custom_activation)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## G_DG block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_values(x):\n",
    "    outcomes, indices = x\n",
    "\n",
    "    r = K.arange(K.shape(indices)[0])\n",
    "    tiint = K.reshape(K.cast(indices,dtype='int32'),(-1,))\n",
    "    idx = K.cast(K.stack([r,tiint],axis=-1),dtype='int32')\n",
    "    \n",
    "    return K.batch_flatten(Lambda(lambda x: tf.gather_nd(x[0],x[1]))([outcomes,idx]))\n",
    "\n",
    "\n",
    "class G_DG():\n",
    "    def __init__(self,data):\n",
    "        \n",
    "        self.data = data\n",
    "        self.pat_features = self.data.n_features\n",
    "        self.pat_shape = (self.pat_features,)\n",
    "        self.num_treatments = 2\n",
    "        self.latent_dim = self.num_treatments-1\n",
    "        self.a = 0.1\n",
    "        \n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "#         self.check_intermediate_layers()\n",
    "        self.build_model()\n",
    "\n",
    "    def check_intermediate_layers(self):\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "                                   optimizer=self.optimizer)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,))\n",
    "        treatment = Input(shape=(self.num_treatments,))\n",
    "        outcome = Input(shape=(1,))\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        treatment_indices = Input(shape=(1,),dtype='int32')\n",
    "        \n",
    "        gen_y = self.generator([pat, treatment, outcome, noise])                \n",
    "        \n",
    "        y_bar = Lambda(self.replace_values)([gen_y, treatment_indices, outcome])\n",
    "        \n",
    "        z=Model([pat,treatment,outcome,noise,treatment_indices],gen_y)\n",
    "        \n",
    "        pat = np.arange(self.pat_features * BATCH_SIZE).reshape((BATCH_SIZE,self.pat_features))\n",
    "        treatment = one_hot(np.random.randint(0,2,BATCH_SIZE))\n",
    "        outcome = np.random.randint(0,2,(BATCH_SIZE,1))\n",
    "        noise = np.random.uniform(-1,2,(BATCH_SIZE,self.latent_dim))\n",
    "        treatment_indices = np.argmax(treatment,axis=1)\n",
    "\n",
    "        gen_y = z.predict([pat,treatment,outcome,noise,treatment_indices])\n",
    "        ybar = zz.predict([pat,treatment,outcome,noise,treatment_indices])\n",
    "        \n",
    "    def build_model(self):\n",
    "        \n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "#         self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "#                                    optimizer=self.optimizer)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,))\n",
    "        treatment = Input(shape=(self.num_treatments,))\n",
    "        outcome = Input(shape=(1,))\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        treatment_indices = Input(shape=(1,),dtype='int32')\n",
    "        \n",
    "        gen_y = self.generator([pat, treatment, outcome, noise])                \n",
    "        \n",
    "        predicted_outcome_of_real_treatment = Lambda(get_values,name='predicted_outcome_of_real_treatment')([gen_y,treatment_indices])\n",
    "\n",
    "        y_bar = Lambda(self.replace_values,name='y_bar')([gen_y, treatment_indices, outcome])\n",
    "        \n",
    "        valid = self.discriminator([pat, y_bar])        \n",
    "        \n",
    "        self.combined = Model([pat, treatment, outcome, noise, treatment_indices], [valid, predicted_outcome_of_real_treatment])\n",
    "        \n",
    "        self.combined.compile(loss=['binary_crossentropy','mean_squared_error'],\n",
    "                              loss_weights=[1.,self.a],\n",
    "                              optimizer=self.optimizer)\n",
    "        \n",
    "    def replace_values(self,x):\n",
    "        outs, indices, values = x\n",
    "\n",
    "        #this is due to a strange bug between lambda and integers....\n",
    "        indices = K.cast(indices, 'int32')\n",
    "\n",
    "        #create one_hot indices\n",
    "        one_hot_indices = K.one_hot(indices, self.num_treatments) #size is the size of gen_out\n",
    "        one_hot_indices = K.batch_flatten(one_hot_indices)\n",
    "\n",
    "        #have the desired values at their correct positions\n",
    "        values_to_use = one_hot_indices * values\n",
    "\n",
    "        #if values are 0, use gen_out, else use values\n",
    "        return K.switch(K.equal(values_to_use, 0), outs, values_to_use)\n",
    "        \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.pat_features+self.num_treatments+1+self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.6))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.6))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.6))  \n",
    "        model.add(Dense(self.num_treatments, activation='hard_sigmoid'))\n",
    "#         model.summary()\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,),dtype='float32')\n",
    "        treatment = Input(shape=(self.num_treatments,),dtype='float32')\n",
    "        real_outcome = Input(shape=(1,), dtype='float32')\n",
    "        noise = Input(shape=(self.latent_dim,),dtype='float32')\n",
    "\n",
    "        model_input = concatenate([pat, treatment, real_outcome, noise])\n",
    "\n",
    "        outcomes = model(model_input)\n",
    "        \n",
    "        return Model([pat, treatment, real_outcome, noise], outcomes)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.pat_features+self.num_treatments))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512,activation='sigmoid'))\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(Dense(self.num_treatments, activation='sigmoid', name='treatment_probs'))\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,), dtype='float32')\n",
    "        \n",
    "        y_bar = Input(shape=(self.num_treatments,), dtype='float32')   \n",
    "        \n",
    "        model_input = concatenate([pat,y_bar])\n",
    "        \n",
    "        treatment_probs = model(model_input)\n",
    "                          \n",
    "        return Model([pat, y_bar], treatment_probs)\n",
    "    \n",
    "\n",
    "    def train(self, epochs, split_date='2015-11-01', batch_size=BATCH_SIZE):\n",
    "        \n",
    "        # Load the dataset\n",
    "        X_train, y_train, t_train, _ = self.data.train[split_date]\n",
    "        \n",
    "        # Configure input\n",
    "        X_train = X_train.values.astype(np.float32)\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        t_train = t_train.reshape(-1,self.num_treatments)\n",
    "                \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of patients\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            pats, treatments, real_outcomes = X_train[idx], t_train[idx], y_train[idx]\n",
    "            \n",
    "            treatment_indices = np.argmax(treatments,axis=1).reshape(-1,1).astype(np.int64)\n",
    "            noise = np.random.uniform(-1, 2, (batch_size, self.latent_dim))\n",
    "                        \n",
    "            # Generate y | (X,t,y_f)\n",
    "            gen_y = self.generator.predict([pats, treatments, real_outcomes, noise])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "            \n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch([pats, treatments, real_outcomes, noise, treatment_indices], [treatments, real_outcomes])\n",
    "            \n",
    "            # Plot the progress\n",
    "            if epoch % 200 == 0:\n",
    "                print (\"{}: D loss {}, G loss: {}\".format(epoch, g_loss[1], g_loss[2]))            \n",
    "\n",
    "        self.trained=datetime.datetime.now()\n",
    "        \n",
    "    \n",
    "    def generate_complete_dataset(self):\n",
    "\n",
    "        X = self.data.df.drop(columns=['dialysis','mort12mo']).values\n",
    "        y = self.data.df['mort12mo'].values\n",
    "        t = one_hot(self.data.df['dialysis'].values)\n",
    "\n",
    "        treatment_indices = np.argmax(t,axis=1)\n",
    "        noise = np.random.uniform(-1, 2, (X.shape[0], self.latent_dim))\n",
    "\n",
    "        # Generate y | (X,t,y_f)\n",
    "        gen_y = self.generator.predict([X, t, y, noise])\n",
    "\n",
    "        y_bar = gen_y.copy()\n",
    "        \n",
    "        for k in range(gen_y.shape[0]):\n",
    "            y_bar[k,treatment_indices[k]]=y[k]\n",
    "        \n",
    "        self.data.complete_fake_y = gen_y\n",
    "        self.data.complete_real_y = y_bar\n",
    "        \n",
    "# if __name__ == '__main__':\n",
    "#     cgan = CGAN()\n",
    "#     cgan.train(epochs=20000, batch_size=32, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-cd64f9eb0fc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgdg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mG_DG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgdg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3f93649005e1>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m#         self.check_intermediate_layers()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcheck_intermediate_layers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3f93649005e1>\u001b[0m in \u001b[0;36mbuild_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mgen_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtreatment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutcome\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mpredicted_outcome_of_real_treatment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'predicted_outcome_of_real_treatment'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgen_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtreatment_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;31m#         print(K.int_shape(predicted_outcome_of_real_treatment))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;31m#         print(K.shape(predicted_outcome_of_real_treatment))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Actually call the layer,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0;31m# collecting output(s), mask(s), and shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0moutput_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3f93649005e1>\u001b[0m in \u001b[0;36mget_values\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtiint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    472\u001b[0m             if all([s is not None\n\u001b[1;32m    473\u001b[0m                     for s in to_list(input_shape)]):\n\u001b[0;32m--> 474\u001b[0;31m                 \u001b[0moutput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcompute_output_shape\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    643\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m                     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhas_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0marguments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mask'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompute_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-3f93649005e1>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtiint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mgather_nd\u001b[0;34m(params, indices, name)\u001b[0m\n\u001b[1;32m   3238\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_ctx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_eager_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3239\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 3240\u001b[0;31m         \"GatherNd\", params=params, indices=indices, name=name)\n\u001b[0m\u001b[1;32m   3241\u001b[0m     \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3242\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    607\u001b[0m               _SatisfiesTypeConstraint(base_type,\n\u001b[1;32m    608\u001b[0m                                        \u001b[0m_Attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 609\u001b[0;31m                                        param_name=input_name)\n\u001b[0m\u001b[1;32m    610\u001b[0m             \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m             \u001b[0minferred_from\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_attr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_SatisfiesTypeConstraint\u001b[0;34m(dtype, attr_def, param_name)\u001b[0m\n\u001b[1;32m     58\u001b[0m           \u001b[0;34m\"allowed values: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m           (param_name, dtypes.as_dtype(dtype).name,\n\u001b[0;32m---> 60\u001b[0;31m            \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Value passed to parameter 'indices' has DataType float32 not in list of allowed values: int32, int64"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "gdg = G_DG(datas[0])\n",
    "gdg.train(epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdg.generate_complete_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class I_DI():\n",
    "    def __init__(self,data):\n",
    "        \n",
    "        self.data = data\n",
    "        self.pat_features = self.data.n_features\n",
    "        self.pat_shape = (self.pat_features,)\n",
    "        self.num_treatments = 2\n",
    "        self.latent_dim = self.num_treatments\n",
    "        self.b = 2.\n",
    "        \n",
    "        \n",
    "        self.optimizer = Adam(0.0002, 0.5)\n",
    "        \n",
    "#         self.check_intermediate_layers()\n",
    "        self.build_model()\n",
    "\n",
    "    def check_intermediate_layers(self):\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "                                   optimizer=self.optimizer)\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,))\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        \n",
    "        gen_y = self.generator([pat, treatment, outcome, noise])                \n",
    "        \n",
    "        y_bar = Lambda(self.replace_values)([gen_y, treatment_indices, outcome])\n",
    "        \n",
    "        z=Model([pat,noise,treatment_indices],gen_y)\n",
    "        zz=Model([pat,noise,treatment_indices],y_bar)\n",
    "        \n",
    "        pat = np.arange(self.pat_features * BATCH_SIZE).reshape((BATCH_SIZE,self.pat_features))\n",
    "        noise = np.random.uniform(-1,2,(BATCH_SIZE,self.latent_dim))\n",
    "\n",
    "        gen_y = z.predict([pat,treatment,outcome,noise,treatment_indices])\n",
    "        ybar = zz.predict([pat,treatment,outcome,noise,treatment_indices])\n",
    "        \n",
    "    def build_model(self):\n",
    "        \n",
    "        self.discriminator = self.build_discriminator()        \n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,))\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        treatment_indices = Input(shape=(1,))\n",
    "        outcome = Input(shape=(1,))\n",
    "        real_indicator = Input(shape=(1,))\n",
    "\n",
    "        gen_y = self.generator([pat, noise])\n",
    "        \n",
    "        predicted_outcome_of_real_treatment = Lambda(get_values,name='predicted_outcome_of_real_treatment')([gen_y,treatment_indices])\n",
    "\n",
    "        y_bar = Lambda(self.replace_values,name='y_bar')([gen_y, treatment_indices, outcome])\n",
    "\n",
    "        y = K.switch(K.equal(real_indicator,0),gen_y,y_bar)\n",
    "    \n",
    "        pred_real = self.discriminator([pat, y])        \n",
    "        \n",
    "        self.combined = Model([pat, noise, treatment_indices, outcome, real_indicator], [pred_real, predicted_outcome_of_real_treatment])\n",
    "        \n",
    "        self.combined.compile(loss=['binary_crossentropy','mean_squared_error'],\n",
    "                              loss_weights=[1.,self.b],\n",
    "                              optimizer=self.optimizer)\n",
    "   \n",
    "\n",
    "    def replace_values(self,x):\n",
    "        outs, indices, values = x\n",
    "\n",
    "        #this is due to a strange bug between lambda and integers....\n",
    "        indices = K.cast(indices, 'int32')\n",
    "\n",
    "        #create one_hot indices\n",
    "        one_hot_indices = K.one_hot(indices, self.num_treatments) #size is the size of gen_out\n",
    "        one_hot_indices = K.batch_flatten(one_hot_indices)\n",
    "\n",
    "        #have the desired values at their correct positions\n",
    "        values_to_use = one_hot_indices * values\n",
    "\n",
    "        #if values are 0, use gen_out, else use values\n",
    "        return K.switch(K.equal(values_to_use, 0), outs, values_to_use)\n",
    "        \n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.pat_features+self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.6))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.6))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.6))  \n",
    "        model.add(Dense(self.num_treatments, activation='hard_sigmoid'))\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,),dtype='float32')\n",
    "        noise = Input(shape=(self.latent_dim,),dtype='float32')\n",
    "\n",
    "        model_input = concatenate([pat, noise])\n",
    "\n",
    "        outcomes = model(model_input)\n",
    "        \n",
    "        return Model([pat, noise], outcomes)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512, input_dim=self.pat_features+self.num_treatments))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(512,activation='sigmoid'))\n",
    "        model.add(Dense(512,activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid', name='real_prob'))\n",
    "\n",
    "        pat = Input(shape=(self.pat_features,), dtype='float32')\n",
    "        outcome = Input(shape=(self.num_treatments,), dtype='float32')   \n",
    "        \n",
    "        model_input = concatenate([pat,outcome])\n",
    "        \n",
    "        treatment_probs = model(model_input)\n",
    "                          \n",
    "        return Model([pat, outcome], treatment_probs)\n",
    "    \n",
    "\n",
    "    def train(self, epochs, split_date='2017-11-01', batch_size=BATCH_SIZE):\n",
    "        \n",
    "        # Load the dataset\n",
    "        X_train, y_train, t_train, _ = self.data.train[split_date]\n",
    "        \n",
    "        # Configure input\n",
    "        X_train = X_train.values.astype(np.float32)\n",
    "        y_train = y_train.reshape(-1,1)\n",
    "        t_train = t_train.reshape(-1,self.num_treatments)\n",
    "                \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of patients\n",
    "            idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            pats, treatments, real_outcomes = X_train[idx], t_train[idx], y_train[idx]\n",
    "            \n",
    "            real_indicators = np.random.randint(0,2,batch_size).reshape(-1,1)\n",
    "            \n",
    "            treatment_indices = np.argmax(treatments,axis=1).reshape(-1,1)\n",
    "            noise = np.random.uniform(-1, 2, (batch_size, self.latent_dim))\n",
    "                        \n",
    "            # Generate y | (X,t,y_f)\n",
    "            gen_y = self.generator.predict([pats, noise])\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            loss = self.combined.train_on_batch([pats, noise, treatment_indices, outcome, real_indicators], [real_indicators, real_outcomes])\n",
    "            \n",
    "            # Plot the progress\n",
    "            if epoch % 200 == 0:\n",
    "                print (\"{} [sum, dis, gen] loss: {}\".format(epoch, loss))            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
